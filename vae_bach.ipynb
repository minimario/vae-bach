{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae music21?",
      "provenance": [],
      "authorship_tag": "ABX9TyNtckcGrUdiR0mwuDDimtPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minimario/vae-bach/blob/main/vae_bach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "ziGZ655E5weB",
        "outputId": "537be127-8713-4d08-b87c-2bba9c24ed8e"
      },
      "source": [
        "%pip install --upgrade music21"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting music21\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/0e/b9bf3530203f6e6ed1f04d4352ac421aef2429ab77c416ff583dd6d58597/music21-6.3.0.tar.gz (19.2MB)\n",
            "\u001b[K     |████████████████████████████████| 19.2MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet in /usr/local/lib/python3.6/dist-packages (from music21) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from music21) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from music21) (8.6.0)\n",
            "Collecting webcolors\n",
            "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n",
            "Building wheels for collected packages: music21\n",
            "  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for music21: filename=music21-6.3.0-cp36-none-any.whl size=21888021 sha256=f34dad481f42726171089a178b2702c0eab6962df92764db71cb0dd2f8367e6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e8/2c/eed32afec2b6c6f945a17280c4e4df1cf2e8cd15ebe1025680\n",
            "Successfully built music21\n",
            "Installing collected packages: webcolors, music21\n",
            "  Found existing installation: music21 5.5.0\n",
            "    Uninstalling music21-5.5.0:\n",
            "      Successfully uninstalled music21-5.5.0\n",
            "Successfully installed music21-6.3.0 webcolors-1.11.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "music21"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bf9XWqc6GDp",
        "outputId": "f1f79ec9-2f6c-49c5-955f-da1f889d5dd9"
      },
      "source": [
        "print(music21.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55_THJcNdYwn"
      },
      "source": [
        "import music21\n",
        "import music21 as m21\n",
        "from music21 import *\n",
        "import keras\n",
        "import numpy as np\n",
        "paths = corpus.getComposer('bach')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh9zviWYdarC"
      },
      "source": [
        "bach = []\n",
        "for i in paths:\n",
        "    s = corpus.parse(i)\n",
        "    bach.append(s)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JudlP6-UdcMl"
      },
      "source": [
        "def transpose(song):\n",
        "    parts = song.getElementsByClass(music21.stream.Part)\n",
        "    measures_part0 = parts[0].getElementsByClass(music21.stream.Measure)\n",
        "    \n",
        "    key = measures_part0[0].getElementsByClass(music21.key.Key)\n",
        "    \n",
        "    if len(key) != 0:\n",
        "        key = key[0]\n",
        "    else:\n",
        "        key = song.analyze(\"key\")\n",
        "\n",
        "    # get interval for transposition. E.g., Bmaj -> Cmaj\n",
        "    if key.mode == \"major\":\n",
        "        interval = music21.interval.Interval(key.tonic, music21.pitch.Pitch(\"C\"))\n",
        "    elif key.mode == \"minor\":\n",
        "        interval = music21.interval.Interval(key.tonic, music21.pitch.Pitch(\"A\"))\n",
        "\n",
        "    # transpose song by calculated interval\n",
        "    tranposed_song = song.transpose(interval)\n",
        "    return tranposed_song"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRBXFZgCddkc"
      },
      "source": [
        "def encode_song(song, time_step=0.25):\n",
        "    \"\"\"Converts a score into a time-series-like music representation. Each item in the encoded list represents 'min_duration'\n",
        "    quarter lengths. The symbols used at each step are: integers for MIDI notes, 'r' for representing a rest, and '_'\n",
        "    for representing notes/rests that are carried over into a new time step. Here's a sample encoding:\n",
        "\n",
        "        [\"r\", \"_\", \"60\", \"_\", \"_\", \"_\", \"72\" \"_\"]\n",
        "\n",
        "    :param song (m21 stream): Piece to encode\n",
        "    :param time_step (float): Duration of each time step in quarter length\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    encoded_song = []\n",
        "\n",
        "    for event in song.flat.notesAndRests:\n",
        "\n",
        "        # handle notes\n",
        "        if isinstance(event, m21.note.Note):\n",
        "            symbol = event.pitch.midi # 60\n",
        "        # handle rests\n",
        "        elif isinstance(event, m21.note.Rest):\n",
        "            symbol = \"r\"\n",
        "\n",
        "        # convert the note/rest into time series notation\n",
        "        steps = int(event.duration.quarterLength / time_step)\n",
        "        for step in range(steps):\n",
        "\n",
        "            # if it's the first time we see a note/rest, let's encode it. Otherwise, it means we're carrying the same\n",
        "            # symbol in a new time step\n",
        "            if step == 0:\n",
        "                encoded_song.append(symbol)\n",
        "            else:\n",
        "                encoded_song.append(\"_\")\n",
        "\n",
        "    # cast encoded song to str\n",
        "    encoded_song = list(map(str, encoded_song))\n",
        "\n",
        "    return encoded_song\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P67tlf3hdgLf"
      },
      "source": [
        "bach_transposed = []\n",
        "for s in bach:\n",
        "    bach_transposed.append(transpose(s))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQKyv88AdhL-"
      },
      "source": [
        "def transpose_octave(encoding, direction):\n",
        "    \"\"\"\n",
        "    takes in a string encoding and transposes it up/down an octave\n",
        "    direction: one of 'up', 'down'\n",
        "    \"\"\"\n",
        "    transposed_encoding = []\n",
        "    for i in encoding:\n",
        "        if i in '_r':\n",
        "            transposed_encoding.append(i)\n",
        "        else:\n",
        "            if direction == 'up':\n",
        "                transposed_encoding.append(str(int(i)+12))\n",
        "            else:\n",
        "                transposed_encoding.append(str(int(i)-12))\n",
        "    return transposed_encoding"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YpKujyfdiAW"
      },
      "source": [
        "encodings = []\n",
        "\n",
        "for b in bach_transposed:\n",
        "    for part in b.parts:\n",
        "      if part.partName in ['Soprano', 'Tenor', 'Alto', 'Bass']:\n",
        "        part_encoded = encode_song(part)\n",
        "        if part.partName == 'Soprano':\n",
        "            encodings.append(transpose_octave(part_encoded, 'down'))\n",
        "        elif part.partName == 'Bass':\n",
        "            encodings.append(transpose_octave(part_encoded, 'up'))\n",
        "        else:\n",
        "            encodings.append(part_encoded)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd1-aWSedixZ"
      },
      "source": [
        "import itertools\n",
        "mappings = {}\n",
        "inv_mappings = {}\n",
        "distinct_symbols = list(set(itertools.chain.from_iterable(encodings)))\n",
        "for i, s in enumerate(distinct_symbols):\n",
        "    mappings[s] = i\n",
        "    inv_mappings[i] = s"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Twku8Xdjub"
      },
      "source": [
        "def compress(songs):\n",
        "  return [mappings[symbol] for symbol in songs]\n",
        "\n",
        "def decompress(ints):\n",
        "  return [inv_mappings[num] for num in ints]\n",
        "  "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOH5IDgGdkjN"
      },
      "source": [
        "mapped_encodings = list(map(compress, encodings))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWxYGs7idlXd"
      },
      "source": [
        "len_64_segments = []\n",
        "for encoding in mapped_encodings:\n",
        "    for j in range(0, len(encoding), 4):\n",
        "        if j+64 <= len(encoding) and encoding[j] != mappings['_']:\n",
        "            len_64_segments.append(encoding[j:j+64])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_54GjiHdnE0",
        "outputId": "1f93a79c-9a9a-4ed0-a317-a298d64cde48"
      },
      "source": [
        "inputs = np.array(len_64_segments)\n",
        "inputs_cat = keras.utils.to_categorical(inputs)\n",
        "print(inputs_cat.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57336, 64, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gia440weA5xm",
        "outputId": "e0ac80d6-652c-47b6-8e0f-af0131687623"
      },
      "source": [
        "import random\n",
        "r = random.randint(0, len(inputs_cat)-1)\n",
        "print(inputs[r])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 39 39 39  1 39 19 39 24 39 39 39 19 39  1 39 43 39 39 39 21 39 24 39\n",
            " 19 39 39 39 24 39 39 39  1 39  4 39 24 39 39 39  9 39 34 39 16 39 39 39\n",
            " 16 39 39 39 43 39  1 39  4 39 24 39 16 39 39 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sN0LtI0fLdg",
        "outputId": "7c1843f7-5fa2-4dc7-f021-398410239836"
      },
      "source": [
        "inputs_cat = inputs_cat.reshape((inputs_cat.shape[0], -1))\n",
        "print(inputs_cat.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57336, 2880)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYlQfpIe9Em"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgfmGcPafIuR",
        "outputId": "2dc5c825-f934-490f-95c0-82dce66e740b"
      },
      "source": [
        "input_shape = inputs_cat.shape[1]\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(input_shape,1))\n",
        "x = layers.Conv1D(32, 8, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv1D(64, 8, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 2880, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 1440, 32)     288         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1440, 32)     128         conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 720, 64)      16448       batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 720, 64)      256         conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 46080)        0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 16)           737296      flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 256)          4352        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 256)          4352        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampling_4 (Sampling)           (None, 256)          0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 763,120\n",
            "Trainable params: 762,928\n",
            "Non-trainable params: 192\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7XOu5usfhT7",
        "outputId": "4f48b325-5e48-4ac8-da29-48fa69c43f52"
      },
      "source": [
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(720 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((720, 64))(x)\n",
        "x = layers.Conv1DTranspose(64, 8, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv1DTranspose(32, 8, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "decoder_outputs = layers.Conv1DTranspose(1, 8, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 46080)             11842560  \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 720, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_12 (Conv1DT (None, 1440, 64)          32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1440, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_13 (Conv1DT (None, 2880, 32)          16416     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 2880, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_14 (Conv1DT (None, 2880, 1)           257       \n",
            "=================================================================\n",
            "Total params: 11,892,449\n",
            "Trainable params: 11,892,257\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEWrwZc8fivm"
      },
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = encoder(data)\n",
        "            reconstruction = decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                keras.losses.binary_crossentropy(data, reconstruction)\n",
        "            )\n",
        "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            kl_loss = tf.reduce_mean(kl_loss)\n",
        "            kl_loss *= -0.5\n",
        "            recon_weight = 0.8\n",
        "            total_loss = recon_weight * reconstruction_loss + (1 - recon_weight) * kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "M1dgMDwTgDrM",
        "outputId": "c26bf0f1-5687-4a65-b8e7-de267b20eb5a"
      },
      "source": [
        "vae_inputs = inputs_cat[:, :, np.newaxis]\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(vae_inputs, epochs=30, batch_size=128)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "448/448 [==============================] - 46s 99ms/step - loss: 0.0487 - reconstruction_loss: 0.0578 - kl_loss: 0.0126\n",
            "Epoch 2/30\n",
            "448/448 [==============================] - 44s 99ms/step - loss: 0.0283 - reconstruction_loss: 0.0338 - kl_loss: 0.0064\n",
            "Epoch 3/30\n",
            "448/448 [==============================] - 44s 99ms/step - loss: 0.0266 - reconstruction_loss: 0.0326 - kl_loss: 0.0029\n",
            "Epoch 4/30\n",
            "448/448 [==============================] - 44s 99ms/step - loss: 0.0256 - reconstruction_loss: 0.0312 - kl_loss: 0.0033\n",
            "Epoch 5/30\n",
            "448/448 [==============================] - 44s 99ms/step - loss: 0.0253 - reconstruction_loss: 0.0307 - kl_loss: 0.0036\n",
            "Epoch 6/30\n",
            "448/448 [==============================] - 44s 98ms/step - loss: 0.0252 - reconstruction_loss: 0.0305 - kl_loss: 0.0038\n",
            "Epoch 7/30\n",
            "448/448 [==============================] - 44s 98ms/step - loss: 0.0251 - reconstruction_loss: 0.0304 - kl_loss: 0.0039\n",
            "Epoch 8/30\n",
            "448/448 [==============================] - 44s 98ms/step - loss: 0.0250 - reconstruction_loss: 0.0303 - kl_loss: 0.0040\n",
            "Epoch 9/30\n",
            "448/448 [==============================] - 44s 98ms/step - loss: 0.0250 - reconstruction_loss: 0.0302 - kl_loss: 0.0040\n",
            "Epoch 10/30\n",
            "448/448 [==============================] - 44s 98ms/step - loss: 0.0250 - reconstruction_loss: 0.0302 - kl_loss: 0.0041\n",
            "Epoch 11/30\n",
            "448/448 [==============================] - 44s 98ms/step - loss: 0.0249 - reconstruction_loss: 0.0301 - kl_loss: 0.0041\n",
            "Epoch 12/30\n",
            " 91/448 [=====>........................] - ETA: 35s - loss: 0.0250 - reconstruction_loss: 0.0302 - kl_loss: 0.0042"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-cff55676b930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnj8Jlme-Iqk",
        "outputId": "dbcf7bbd-7e9e-413e-9ae7-67b2bc5a2329"
      },
      "source": [
        "latent_input = np.random.normal(0, 1, (1, latent_dim))\n",
        "decoded = decoder.predict(latent_input).reshape((64, 45))\n",
        "melody = np.argmax(decoded, axis=1)\n",
        "song = decompress(list(melody))\n",
        "save_melody(song)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<music21.stream.Stream 0x7f7d4b46dac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-qyIvUF9IXs"
      },
      "source": [
        "def save_melody(melody, step_duration=0.25, format=\"midi\", file_name=\"mel.mid\"):\n",
        "    \"\"\"Converts a melody into a MIDI file\n",
        "\n",
        "    :param melody (list of str):\n",
        "    :param min_duration (float): Duration of each time step in quarter length\n",
        "    :param file_name (str): Name of midi file\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # create a music21 stream\n",
        "    stream = m21.stream.Stream()\n",
        "\n",
        "    start_symbol = None\n",
        "    step_counter = 1\n",
        "\n",
        "    # parse all the symbols in the melody and create note/rest objects\n",
        "    for i, symbol in enumerate(melody):\n",
        "        # handle case in which we have a note/rest\n",
        "        if symbol != \"_\" or i + 1 == len(melody):\n",
        "            # ensure we're dealing with note/rest beyond the first one\n",
        "            if start_symbol is not None:\n",
        "                quarter_length_duration = step_duration * step_counter # 0.25 * 4 = 1\n",
        "                # handle rest\n",
        "                if start_symbol == \"r\":\n",
        "                    m21_event = m21.note.Rest(quarterLength=quarter_length_duration)\n",
        "                # handle note\n",
        "                else:\n",
        "                    m21_event = m21.note.Note(int(start_symbol), quarterLength=quarter_length_duration)\n",
        "                stream.append(m21_event)\n",
        "                # reset the step counter\n",
        "                step_counter = 1\n",
        "            start_symbol = symbol\n",
        "        # handle case in which we have a prolongation sign \"_\"\n",
        "        else:\n",
        "            step_counter += 1\n",
        "    # write the m21 stream to a midi file\n",
        "    stream.write(format, file_name)\n",
        "    return stream"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SRyjImN_YcQ",
        "outputId": "1597dd6c-1f03-4263-f490-5cb4cee5b764"
      },
      "source": [
        "print(song)\n",
        "s = save_melody(song)\n",
        "for i in s:\n",
        "  print(i)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['60', '_', '_', '_', '_', '_', '_', '_', '60', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_', '60', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_', '60', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n",
            "<music21.note.Note C>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}